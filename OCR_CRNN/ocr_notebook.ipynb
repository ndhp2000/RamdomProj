{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ocr_notebook.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuGlYfm3VcEv",
        "colab_type": "code",
        "outputId": "6579b998-ce78-449d-a00c-f04f2038578e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# !wget https://www.robots.ox.ac.uk/~vgg/data/text/mjsynth.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-21 13:44:08--  https://www.robots.ox.ac.uk/~vgg/data/text/mjsynth.tar.gz\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10678411583 (9.9G) [application/x-gzip]\n",
            "Saving to: ‘mjsynth.tar.gz’\n",
            "\n",
            "mjsynth.tar.gz      100%[===================>]   9.94G  66.5MB/s    in 2m 35s  \n",
            "\n",
            "2019-08-21 13:46:43 (65.9 MB/s) - ‘mjsynth.tar.gz’ saved [10678411583/10678411583]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oQ52cxrVeWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !tar zxf mjsynth.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87Bs_gxyffW1",
        "colab_type": "code",
        "outputId": "fc77c743-91ec-4018-a2f9-01a6a3cbe329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# Implement CRNN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "\n",
        "    def __init__(self,c_img):\n",
        "        super(CRNN, self).__init__()\n",
        "        self.c_img = c_img\n",
        "        self.conv1 = nn.Conv2d(c_img, 64 ,3, stride=1,padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128,3, stride=1,padding=1)\n",
        "        self.conv3_1 = nn.Conv2d(128, 256,3, stride=1,padding=1)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256,3, stride=1,padding=1)\n",
        "        self.conv4 = nn.Conv2d(256, 512,3, stride=1,padding=1)\n",
        "        self.conv5 = nn.Conv2d(512, 512,3, stride=1,padding=1)\n",
        "        self.conv6 = nn.Conv2d(512, 512,2, stride=1,padding=0)\n",
        "        self.relu = nn.ReLU(True)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(512)\n",
        "        self.pool22s2 = nn.MaxPool2d(2, stride=2)\n",
        "        self.pool12s2 = nn.MaxPool2d((1,2), stride=2)\n",
        "        self.rnn = nn.LSTM(512, 256, num_layers=2,bidirectional=True)\n",
        "        # with blank\n",
        "        self.maplin = nn.Linear(512,11)\n",
        "\n",
        "      \n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool22s2(x)\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool22s2(x)\n",
        "        x = self.relu(self.conv3_1(x))\n",
        "        x = self.relu(self.conv3_2(x))\n",
        "        x = self.pool12s2(x)\n",
        "        x = self.relu(self.batchnorm2(self.conv4(x)))\n",
        "        x = self.relu(self.batchnorm2(self.conv5(x)))\n",
        "        x = self.pool12s2(x)\n",
        "        x = self.relu(self.conv6(x))\n",
        "        # x (batch, 512, 1, seq_len)\n",
        "        # need to resize it to (seq len, batch, 512)\n",
        "        x, _ = self.rnn(x.permute(3,0,1,2).squeeze(3))\n",
        "        \n",
        "        x = self.maplin(x) \n",
        "        # x (seqlen, 1, class_size)\n",
        "\n",
        "        return x.log_softmax(2)\n",
        "\n",
        "\n",
        "net = CRNN(1).cuda()\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CRNN(\n",
            "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv6): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
            "  (relu): ReLU(inplace)\n",
            "  (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (batchnorm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool22s2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (pool12s2): MaxPool2d(kernel_size=(1, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (rnn): LSTM(512, 256, num_layers=2, bidirectional=True)\n",
            "  (maplin): Linear(in_features=512, out_features=11, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_uBTNcipNSz",
        "colab_type": "code",
        "outputId": "f680f5ed-5b23-43b7-f613-703d0eeb617a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "inp = torch.randn(32,1,32,64).cuda()\n",
        "out = net(inp)\n",
        "print(out.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 32, 11])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNLpacu_Y13T",
        "colab_type": "code",
        "outputId": "5c108464-86a0-4f88-b196-a3191a2223a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "inp.permute(3,0,1,2).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 32, 1, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHiQ6fzXsLW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Example training with CTC Loss\n",
        "T = 5      # Input sequence length\n",
        "C = 11      # Number of classes (including blank)\n",
        "N = 1      # Batch size\n",
        "S = 2      # Target sequence length of longest target in batch\n",
        "S_min = 1  # Minimum target length, for demonstration purposes\n",
        "# Initialize random batch of input vectors, for *size = (T,N,C)\n",
        "input = torch.randn(T, N, C, requires_grad=True)\n",
        "z = torch.ones(1, requires_grad=True)\n",
        "# Initialize random batch of targets (0 = blank, 1:C = classes)\n",
        "target = torch.randint(low=1, high=C, size=(N, S), dtype=torch.long)\n",
        "input_lengths = torch.full(size=(N,), fill_value=T, dtype=torch.long)\n",
        "target_lengths = torch.randint(low=S_min, high=S, size=(N,), dtype=torch.long)\n",
        "if target_lengths == 2: target_lengths -=1\n",
        "ctc_loss = nn.CTCLoss()\n",
        "loss = 999\n",
        "while loss >= 0.005 :\n",
        "  log_inp = F.log_softmax(input*z, dim=2)\n",
        "  loss = ctc_loss(log_inp, target, input_lengths, target_lengths)\n",
        "  loss.backward()\n",
        "  #print('loss:', loss)\n",
        "  with torch.no_grad():\n",
        "    input  -= 0.1*input.grad\n",
        "    input.grad.zero_()\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InBMDAbdCWE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Try training our model with CTC Loss with random input\n",
        "\n",
        "target = torch.randint(low=1, high=11, size=(32, 1), dtype=torch.long)\n",
        "print('target',target)\n",
        "learning_rate = 0.0005\n",
        "ctc_loss = nn.CTCLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "loss = 999\n",
        "while loss >= 0.005 :\n",
        "  pred = net(inp)\n",
        "  print(pred)\n",
        "  input_lengths = torch.full(size=(32,), fill_value=pred.shape[0], dtype=torch.long)\n",
        "  target_lengths = torch.full(size=(32,), fill_value=1, dtype=torch.long)\n",
        "  loss = ctc_loss(pred, target.cuda(), input_lengths, target_lengths)\n",
        "  print(loss)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLe2-ikha7L9",
        "colab_type": "code",
        "outputId": "b7273f11-47ac-41e7-fcec-ae8a6317384a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "target_lengths.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw0Et3VxFY2V",
        "colab_type": "code",
        "outputId": "7a8c0fa4-947c-4020-dd87-fd0454176618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_lengths"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5.8743e-34])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POv2gMicFZr3",
        "colab_type": "code",
        "outputId": "3f4faba1-35e1-4926-a479-1214f2fe8f40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "target_lengths"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbP3fhK6HpxH",
        "colab_type": "code",
        "outputId": "aaa02be5-0641-45a4-b3b6-bd68ecb400a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "pred.exp().max(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(values=tensor([[0.9924],\n",
              "        [0.9992],\n",
              "        [0.9996],\n",
              "        [0.9994],\n",
              "        [0.9987],\n",
              "        [0.9893],\n",
              "        [0.9425],\n",
              "        [0.9877],\n",
              "        [0.9159],\n",
              "        [0.9992],\n",
              "        [0.9977]], grad_fn=<MaxBackward0>), indices=tensor([[10],\n",
              "        [10],\n",
              "        [10],\n",
              "        [10],\n",
              "        [10],\n",
              "        [10],\n",
              "        [ 2],\n",
              "        [ 2],\n",
              "        [ 9],\n",
              "        [ 9],\n",
              "        [ 9]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymev2CZgInBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "# Train with mnist\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.Resize(size=(32,64)),                      \n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.Resize(size=(32,64)), \n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=1, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qIwDIofOn7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train(model, device, train_loader, optimizer, crit, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        input_lengths = torch.full(size=(32,), fill_value=output.shape[0], dtype=torch.long)\n",
        "        target_lengths = torch.full(size=(32,), fill_value=1, dtype=torch.long)\n",
        "        loss = crit(output, target[:,None], input_lengths,target_lengths )\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUgUBRUoPInr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBfuUwE3RPN5",
        "colab_type": "code",
        "outputId": "b57816ab-51db-4beb-e114-7d55b0af1012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model = CRNN(1).to(device)\n",
        "ctc_loss = nn.CTCLoss()\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CRNN(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv6): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (relu): ReLU(inplace)\n",
              "  (batchnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (batchnorm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool22s2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (pool12s2): MaxPool2d(kernel_size=(1, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (rnn): LSTM(512, 256, num_layers=2, bidirectional=True)\n",
              "  (maplin): Linear(in_features=512, out_features=11, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m53TMz7zSM6g",
        "colab_type": "code",
        "outputId": "3cf132e5-3406-4ad7-8074-8d4e3000dcae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.0005, momentum=0.9)\n",
        "\n",
        "for epoch in range(1, 10):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        \n",
        "        input_lengths = torch.full(size=(data.shape[0],), fill_value=output.shape[0], dtype=torch.long)\n",
        "        target_lengths = torch.full(size=(data.shape[0],), fill_value=1, dtype=torch.long)\n",
        "        loss = ctc_loss(output, target+1, input_lengths,target_lengths )\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            # print(output.exp().max(2),target)\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.022355\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.024228\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.039917\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.063912\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.024575\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.023078\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.055987\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.147620\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.010466\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.047551\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.039562\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.006270\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.009279\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.187594\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.048359\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.111051\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.039167\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.021510\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.013386\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.005632\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.015163\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.091062\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.035472\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.004037\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.012774\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.016407\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.018374\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.009328\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.009285\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.003378\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.014789\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.009119\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.011140\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.043802\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.003744\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.048691\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.042081\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.005290\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.195246\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.015858\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.008519\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.006889\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.051119\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.002580\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.016033\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.004863\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.002669\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.005618\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.027028\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.013500\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.015590\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.003815\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.014819\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.008844\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.012260\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.026527\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.011754\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.003692\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.004579\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.004999\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.008115\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.003874\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.003526\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.028149\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.003382\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.009117\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.006280\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.004368\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.011494\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.007665\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.002720\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.002008\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.003052\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.007006\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.005188\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.001668\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.016627\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.003838\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.011845\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.002434\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.009593\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.002808\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.004579\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.027369\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.006068\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.001901\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.133695\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.002754\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.008325\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.002176\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seSrixzbwjXR",
        "colab_type": "code",
        "outputId": "24c2e73c-3703-4bd8-e5eb-e152fdd4bd18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "target_lengths"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([66815232,        0,        0,        2,        1,        2,        2,\n",
              "               2,        3,        2,        4,        2,        5,        2,\n",
              "               6,        2,        6,        2,        7,        2,        8,\n",
              "               2,        9,        2,       10,        2,       11,        2,\n",
              "              12,        2,       13,        2,       13,        2,       14,\n",
              "               2,       15,        2,       16,        2,       17,        2,\n",
              "              18,        2,       19,        2,       20,        2,       20,\n",
              "               2,       21,        2,       22,        2,       23,        2,\n",
              "              24,        2,       25,        2,       26,        2,       27,\n",
              "               1], dtype=torch.int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7b8CnUc4Yte",
        "colab_type": "code",
        "outputId": "e63a97d0-7932-46d2-dbea-5a09d1920b29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "input_lengths"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
              "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
              "        9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9], dtype=torch.int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 253
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qucUJDyn4zbO",
        "colab_type": "code",
        "outputId": "e021e93c-549a-48aa-bc17-e148bd3220ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output.size(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWe9sE8643ht",
        "colab_type": "code",
        "outputId": "62dbf22d-5642-4a2f-a9a7-68765e5ec310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "acc = 0\n",
        "for img,label in test_loader:\n",
        "  img,label = img.cuda(), label.cuda()\n",
        "  pred = model(img).exp().max(2)[1]-1\n",
        "  if pred.max() == label:\n",
        "    acc += 1\n",
        "\n",
        "print('acc:', acc / len(test_loader))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc: 0.9255\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQ3M0VF_7yHP",
        "colab_type": "code",
        "outputId": "b8530688-b08f-4d2f-fa58-a74004d84dbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output.exp().max(2)[1]-1==test_label.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1]], device='cuda:0', dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DfTcS5R8OGR",
        "colab_type": "code",
        "outputId": "e335e737-80df-4cf8-bf88-2a3ba96e56d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_label == 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1], dtype=torch.uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjsJkSx48b4Q",
        "colab_type": "code",
        "outputId": "54a79ed8-3084-4a9c-f20f-b89564c52762",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(test_loader)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBjpNNml8wma",
        "colab_type": "code",
        "outputId": "6b370e6e-88f1-46e5-886a-a14ff8beb5d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "img.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 32, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mJ1EYgGDJTI",
        "colab_type": "code",
        "outputId": "361a20a1-c856-47b7-8f9c-3b2770b85120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred.max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNaXt3PyDS-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}